
import os
import re
import sys
from bs4 import BeautifulSoup

def clean_text(text):
    if not text: return None
    # Remove references like [1], [a]
    text = re.sub(r'\[.*?\]', '', text)
    return text.strip()


def generate_sql_seed(html_content, output_file):
    soup = BeautifulSoup(html_content, 'html.parser')
    tables = soup.find_all('table', {'class': 'wikitable'})
    
    municipalities = []
    
    for i, table in enumerate(tables):
        headers = [th.text.strip().lower() for th in table.find_all('th')]
        
        # Dynamic Column Mapping
        name_idx = -1
        city_idx = -1
        district_idx = -1
        pop_idx = -1
        
        for idx, h in enumerate(headers):
            if 'corporation' in h or 'name' in h: name_idx = idx
            if 'city' in h: city_idx = idx # Prefer explicit city column
            if 'district' in h: district_idx = idx
            if 'pop' in h: pop_idx = idx
            
        # Fallback for City: if no City column, use Name (often same)
        if city_idx == -1: city_idx = name_idx
        
        # If we can't find a Name/Corporation column, skip
        if name_idx == -1:
            # sys.stderr.write(f"Skipping Table {i}: No Name/Corporation header found in {headers}\n")
            continue

        # State detection
        state = "India"
        # Walk up to find the header
        prev = table.find_previous(['h2', 'h3'])
        if prev:
            state = prev.text.replace('[edit]', '').strip()
            
        rows = table.find_all('tr')
        valid_rows = 0
        for row in rows:
            cols = row.find_all(['td', 'th'])
            clean_cols = [clean_text(c.text) for c in cols]
            
            # Skip if row is too short to contain our target data
            if len(clean_cols) <= max(name_idx, city_idx): 
                # sys.stderr.write(f"Row skipped: len={len(clean_cols)}, needed={max(name_idx, city_idx)}\n")
                continue
                
            # Skip header rows repeated in body
            # if 'Corporation' in clean_cols[name_idx] or 'Name' in clean_cols[name_idx]:
            #    continue
                
            try:
                name = clean_cols[name_idx]
                city = clean_cols[city_idx]
                district = clean_cols[district_idx] if district_idx != -1 and len(clean_cols) > district_idx else ''
                
                # Basic Validation
                if not name or len(name) < 3 or name.lower() in ['no', 'none', 'total', 'corporation name', 'name']:
                    # sys.stderr.write(f"Skipping invalid name: {name}\n")
                    continue

                # Population parsing
                population = 'NULL'
                if pop_idx != -1 and len(clean_cols) > pop_idx:
                    try:
                        raw_pop = clean_cols[pop_idx]
                        # Extract first contiguous number sequence of decent length
                        # or just remove non-digits
                        nums = re.sub(r'[^\d]', '', raw_pop)
                        if nums and len(nums) > 4:
                            population = nums
                    except:
                        pass
                
                # Website hunting (ANY link in the row that looks external)
                website = 'NULL'
                links = row.find_all('a', href=True)
                for link in links:
                    href = link['href']
                    if href.startswith('http') and 'wikipedia' not in href and 'archive.org' not in href:
                         website = f"'{href}'"
                         break
                
                # ID Generation
                m_id = f"{city.lower().replace(' ', '_')}_mc"
                m_id =  re.sub(r'[^a-z0-9_]', '', m_id)
                
                if not m_id or m_id == '_mc': continue

                municipalities.append({
                    "id": m_id,
                    "name": name.replace("'", "''"),
                    "city": city.replace("'", "''"),
                    "district": district.replace("'", "''"),
                    "state": state.replace("'", "''"),
                    "population": population,
                    "website": website
                })
                valid_rows += 1
                
            except Exception as e:
                sys.stderr.write(f"Error parsing row in {state}: {e}\n")
                continue
        
        sys.stderr.write(f"Processed Table {i} ({state}): {valid_rows} rows extracted.\n")

    # Write SQL (same as before)
    current_ids = set()
    with open(output_file, 'w') as f:
        f.write("-- Seed Data: Municipalities from Wikipedia\n")
        f.write(f"-- Generated by scripts/generate_muni_seed.py from {len(municipalities)} entries\n\n")
        
        for m in municipalities:
            if m['id'] in current_ids: continue
            current_ids.add(m['id'])
            
            f.write(f"""
INSERT INTO municipalities (id, name, state, district, population, website)
VALUES ('{m['id']}', '{m['name']}', '{m['state']}', '{m['district']}', {m['population']}, {m['website']})
ON CONFLICT (id) DO UPDATE SET
    name = EXCLUDED.name,
    state = EXCLUDED.state,
    district = EXCLUDED.district,
    population = EXCLUDED.population,
    website = EXCLUDED.website;
""")

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python script.py <html_file> <output_sql_file>")
        sys.exit(1)
        
    generate_sql_seed(open(sys.argv[1]).read(), sys.argv[2])
